{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cc94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bq_carrefour import MethodBQ\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3abe209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MethodBQ importado\n",
      "✅ Instancia de MethodBQ creada\n",
      "Instancia creada correctamente.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from bq_carrefour import MethodBQ\n",
    "    print(\"✅ MethodBQ importado\")\n",
    "\n",
    "    bq = MethodBQ(project='gcp-ar-cdg-datos-dev')\n",
    "    print(\"✅ Instancia de MethodBQ creada\")\n",
    "\n",
    "    print(\"Instancia creada correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al instanciar MethodBQ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1c170c",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbf99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52605c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marketshare():\n",
    "    '''\n",
    "    Funcion para refrescar la informacion de la tabla \"MarketShare\" en GCP. Esta tabla alimenta el tablero de Marketshare publicao y en produccion de Control de Gestion\n",
    "\n",
    "    Parametros:\n",
    "    1- market_share_data --> Archivo con informacion del share de Carrefour y el resto de Competidores. (Atento a este punto ya que para cargar de forma correcta este archivo primero se deben limpiar las columnas extra que trae el archivo a la izquiera y normalizar los titulos de las columnas, ya que algunas estan en datetime y otras en strings. Asegurarse de que todas las columnas sean de tipo datetime)\n",
    "\n",
    "    2- padron_data --> Archivo actualizado del padron con la ultima informacion. (Atento a este punto ya que puede sufrir modificaciones el padron y romper la Pipeline. La ultima modificacion que se le hizo al padron fue el cambio de nombre de una columna N° por GSX)\n",
    "    '''\n",
    "    try:\n",
    "        # Cargo la Info del Share\n",
    "        try:\n",
    "            df = pd.read_excel('../data/ms data - octubre.xlsx')\n",
    "\n",
    "        except Exception as e:\n",
    "            return f'Error al cargar la informacion del Share. Detalle: {e}'\n",
    "\n",
    "        # Comienzo a trabajar sobre los cambios en el archivo del Share\n",
    "        # Genero un bucle para convertir los nombres de las columnas y que tengan mas sentido. Si la columna es datetime, entonces se obtiene el nombre del mes (En ingles) y se lo coloca como nuevo nombre concatenado con su año\n",
    "        for col in df.columns:\n",
    "\n",
    "            if isinstance(col, datetime):\n",
    "                month = col.strftime('%B')\n",
    "                year = col.year\n",
    "                new_name = f'{month.lower()} {year}'\n",
    "                df = df.rename(columns={col:str(new_name)})\n",
    "\n",
    "            else:\n",
    "                new_name = col.lower()\n",
    "                df = df.rename(columns={col:new_name})\n",
    "\n",
    "        # Trabajo sobre el numero Operacional\n",
    "        df['succad'] = df['succad'].replace(np.nan, 0)\n",
    "        df['succad'] = df['succad'].astype(int)\n",
    "        df['succad'] = df['succad'].replace(0, 'RESTO')\n",
    "\n",
    "            # Renombro columnas\n",
    "        df = df.rename(columns=\n",
    "            {\n",
    "            'area1_rs':'area',\n",
    "            'area_scentia_rs':'region',\n",
    "            'mercado reporte':'subregion',\n",
    "            'formato_m2_rs':'formato_m2',\n",
    "            'mdo carrefour':'marca',\n",
    "            'bandera carrefour':'formato',\n",
    "            'succad':'numero_operacional'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Doy formato y estandarizo los rangos de superficie\n",
    "        df['formato_m2'] = df['formato_m2'].str.split('-', n=1).str[1].str.replace('-', 'a')\n",
    "\n",
    "        # Genero diccionario Auxiliar con los meses en ingles y castellano\n",
    "        meses_en = {\n",
    "        'january': 'enero',\n",
    "        'february': 'febrero',\n",
    "        'march': 'marzo',\n",
    "        'april': 'abril',\n",
    "        'may': 'mayo',\n",
    "        'june': 'junio',\n",
    "        'july': 'julio',\n",
    "        'august': 'agosto',\n",
    "        'september': 'septiembre',\n",
    "        'october': 'octubre',\n",
    "        'november': 'noviembre',\n",
    "        'december': 'diciembre'\n",
    "        }\n",
    "        # Almaceno los nuevos nombres de las columnas\n",
    "        nuevo_nombre_cols = {}\n",
    "\n",
    "        for col in df.columns:\n",
    "            partes = col.lower().split(' ', 1)\n",
    "            if partes[0] in meses_en:\n",
    "                nuevo_nombre = f\"{meses_en[partes[0]]} {partes[1]}\"\n",
    "                nuevo_nombre_cols[col] = nuevo_nombre\n",
    "\n",
    "        # Cambio los nombres viejos por los nuevos\n",
    "        df = df.rename(columns=nuevo_nombre_cols)\n",
    "\n",
    "        # Saco columnas innecesarias\n",
    "        df = df.drop(columns=['ytd24', 'ytd25'])\n",
    "\n",
    "        # PASO CRITICO / DERRITO EL DF PARA TENER EL DATO DE LAS FECHAS COMO VARIABLE CATEGORICA Y PASAR DE UN FORMATO WIDE A LONG\n",
    "        df = df.melt(id_vars=['area', 'region', 'subregion', 'formato_m2', 'marca', 'formato', 'numero_operacional'], var_name='fecha', value_name='ventas_con_tasa')\n",
    "\n",
    "        # Genero columnas\n",
    "        df['mes'] = df['fecha'].str.split(' ').str[0]\n",
    "        df['año'] = df['fecha'].str.split(' ').str[1]\n",
    "\n",
    "        # Ordeno el DF\n",
    "        df = df[['area', 'region', 'subregion', 'formato_m2', 'marca', 'formato', 'numero_operacional', 'fecha', 'mes', 'año', 'ventas_con_tasa']]\n",
    "\n",
    "        # Me aseguro que la columna Num Op sea Numero\n",
    "        df['numero_operacional'] = df['numero_operacional'].astype(str)\n",
    "\n",
    "        # Me quedo unicamente con los registros que tienen Venta\n",
    "        df = df[df['ventas_con_tasa'] != 0]\n",
    "\n",
    "        # Quito valores nulos\n",
    "        df = df.dropna(axis=0, subset=['ventas_con_tasa'], how='any')\n",
    "\n",
    "        # Convierto las ventas en INT\n",
    "        df['ventas_con_tasa'] = df['ventas_con_tasa'].astype(int)\n",
    "\n",
    "        # Genero nuevas columnas\n",
    "        df['ventas_con_tasa_millones'] = df['ventas_con_tasa'] / 1_000_000\n",
    "        df['ventas_con_tasa_millones'] = df['ventas_con_tasa_millones'].astype(float).round(2)\n",
    "\n",
    "        # Estandarizo los formatos\n",
    "        df['formato'] = df['formato'].replace(\n",
    "            {\n",
    "            'CARREFOUR EXPRESS':'EXPRESS',\n",
    "            'CARREFOUR HIPER':'HIPER',\n",
    "            'CARREFOUR MARKET':'MARKET',\n",
    "            'CARREFOUR MAXI':'MAXI'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Diccionario Auxiliar para generar una columna de \"fecha_parsed\"\n",
    "        meses_a_numero = {\n",
    "            'enero': '01',\n",
    "            'febrero': '02',\n",
    "            'marzo': '03',\n",
    "            'abril': '04',\n",
    "            'mayo': '05',\n",
    "            'junio': '06',\n",
    "            'julio': '07',\n",
    "            'agosto': '08',\n",
    "            'septiembre': '09',\n",
    "            'octubre': '10',\n",
    "            'noviembre': '11',\n",
    "            'diciembre': '12'\n",
    "        }\n",
    "\n",
    "        # Genero columnas auxiliares para generar una columna Datetime\n",
    "        df['numero_mes'] = df['mes'].map(meses_a_numero)\n",
    "        df['fecha_parsed'] = df['numero_mes'] + '/' + '01/' + df['año']\n",
    "        df['fecha_final'] = pd.to_datetime(df['fecha_parsed'])\n",
    "\n",
    "        # Elimino las columnas auxiliares\n",
    "        df = df.drop(columns=['numero_mes', 'fecha_parsed', 'fecha'])\n",
    "\n",
    "        # Genero una variable que capture la fecha en la cual se ejecuta el flujo. Obtengo los datos de la fecha, extraigo el año y el mes. Al mes le resto uno, para obtener el mes \"Vencido\" y asi generar una fecha que me serivirá para filtrar unicamente la informacion del mes vencido para concatenarla al historico que ya esta subido a GCP\n",
    "        fecha_actual = pd.to_datetime(datetime.today().date())\n",
    "        fecha_aux = str(fecha_actual.year) + '/' + str(fecha_actual.month - 1) + '/' + '01'\n",
    "        fecha_comparable = pd.to_datetime(fecha_aux, format='%Y/%m/%d')\n",
    "        \n",
    "        # Filtro la informacion y me quedo unicamente con la informacion del mes que voy a concatenar al Historico\n",
    "        df = df[df['fecha_final'] == fecha_comparable]\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        return f'Hubo un error al intentar transformar la informacion del Marketshare. Detalle de error: {e}'    \n",
    "\n",
    "def padron_marketshare():\n",
    "    '''\n",
    "    Funcion para normalizar el padron y dejarlo Limpio y operativo\n",
    "    '''\n",
    "    try:\n",
    "        ### COMIENZO A TRABAJAR SOBRE EL PADRON ###\n",
    "            # Cargo la Informacion del padron\n",
    "        try:\n",
    "            # Indico que columnas voy a necesitar\n",
    "            cols = ['GSX', 'NOMBRE', 'Fecha apertura', 'FIN DE CIERRE','ORGANIZACIÓN ', 'DIRECTOR EXPLOTACIÓN', 'DIRECTOR OPERACIONAL', 'DIRECTOR / GERENTE REGIONAL', 'SUB REGION', 'DIRECTOR/ GERENTE TIENDA', 'Provincia Tableau', 'M² SALÓN', 'M² PGC', 'M² PFT', 'M² BAZAR', 'M² Electro', 'M² Textil', 'M² Pls', 'M² GALERIAS', 'PROVINCIA', 'M² Parcking', 'CAJAS', 'COD.POSTAL']\n",
    "            pad = pd.read_excel('../data/padron_ms.xlsx', header=17, usecols=cols)\n",
    "\n",
    "        except Exception as e:\n",
    "            return f'Error a la hora de cargar el Padron. Detalle {e}'\n",
    "\n",
    "        # Estandarizo un poco los nombres de las columnas\n",
    "        pad.columns = pad.columns.str.strip().str.lower().str.replace(' /', '').str.replace('/', '').str.replace('.', ' ')\n",
    "\n",
    "        # Quito nulos\n",
    "        pad = pad.dropna(subset=['nombre', 'organización', 'fecha apertura'])\n",
    "\n",
    "        # Me quedo unicamente con formatos validos\n",
    "        pad = pad[pad['organización'].isin(['HIPERMERCADO', 'MAXI', 'Market', 'Express'])]\n",
    "\n",
    "        # Me quedo con valores que no hayan cerrado\n",
    "        pad = pad[pad['fin de cierre'] == '-']\n",
    "\n",
    "        # Quito columna incompleta\n",
    "        pad = pad.drop(columns={'provincia tableau'})\n",
    "\n",
    "        # Renombro la columna completa de provincias\n",
    "        pad = pad.rename(columns={\n",
    "            'provincia':'provincia tableau',\n",
    "            'gsx':'id tienda'\n",
    "        })\n",
    "\n",
    "        # Genero un list aux para bucle abajo\n",
    "        cols = ['m² pgc', 'm² pft', 'm² bazar', 'm² electro', 'm² textil', 'm² pls', 'm² galerias', 'cajas', 'm² parcking']\n",
    "\n",
    "        # Itero sobre cols para estandarizar, rellenar y limpiar nulos\n",
    "        for col in cols:\n",
    "            pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
    "\n",
    "        # Ordeno columnas\n",
    "        pad = pad[['nombre', 'id tienda', 'organización', 'director explotación', 'director operacional', 'director gerente regional', 'sub region', 'director gerente tienda', 'provincia tableau', 'm² salón', 'm² pgc', 'm² pft', 'm² bazar', 'm² electro', 'm² textil', 'm² pls', 'm² galerias', 'cod postal', 'cajas', 'm² parcking']]\n",
    "\n",
    "        # Convierto el codigo postal a String ya que es alfanumerico\n",
    "        pad['cod postal'] = pad['cod postal'].astype(str)\n",
    "\n",
    "        # Genero una nueva columna para identificar la ultima fecha de actualizacion de las tiendas\n",
    "        pad['modificacion'] = datetime.today().strftime('%d/%m/%Y')\n",
    "\n",
    "        # Formateo la fecha y la convierto a String. Como no es util para comprar o utilizar en series de tiempo, sirve igual\n",
    "        pad['modificacion'] = pad['modificacion'].astype('str')\n",
    "\n",
    "        # Reseteo y quito Indice indeseado\n",
    "        pad = pad.reset_index(drop=True)\n",
    "\n",
    "        return pad\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f'Ocurrio un error al intentar correr funcion para transformar padron. Detalle de error {e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01c87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "\n",
    "def crear_tabla_si_no_existe(df: pd.DataFrame, table_id: str, project_id: str):\n",
    "    client = bigquery.Client(project=project_id)\n",
    "\n",
    "    try:\n",
    "        client.get_table(table_id)\n",
    "        print(f\"✅ La tabla {table_id} ya existe\")\n",
    "    except NotFound:\n",
    "        print(f\"⚠️ La tabla {table_id} no existe. Creándola...\")\n",
    "\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_EMPTY\"\n",
    "        )\n",
    "\n",
    "        load_job = client.load_table_from_dataframe(\n",
    "            dataframe=df,\n",
    "            destination=table_id,\n",
    "            job_config=job_config\n",
    "        )\n",
    "\n",
    "        load_job.result()\n",
    "        print(f\"✅ Tabla {table_id} creada correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9ad19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n",
      "C:\\Users\\Juan Mera\\AppData\\Local\\Temp\\ipykernel_7836\\1963488650.py:197: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  pad[col] = pad[col].fillna(0).replace('-', 0).replace('sd', 0).replace('SD', 0).replace('', 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "padron = padron_marketshare()\n",
    "share_data = marketshare()\n",
    "\n",
    "def carga_padron(padron, project_id='gcp-ar-cdg-datos-dev', table_id='gcp-ar-cdg-datos-dev.marketshare_project.padron_test'):\n",
    "    try:\n",
    "        # Paso previo: crear tabla si no existe\n",
    "        crear_tabla_si_no_existe(padron, table_id, project_id)\n",
    "\n",
    "        # Ahora sí: usar MethodBQ normalmente\n",
    "        bq_methods = MethodBQ(project=project_id)\n",
    "        bq_methods.upsert_df_to_bigquery(\n",
    "            df=padron,\n",
    "            table_id=table_id,\n",
    "            mode='merge',\n",
    "            primary_keys=['id tienda']\n",
    "        )\n",
    "\n",
    "        return '✅ Éxito al cargar la información del padrón a GCP'\n",
    "\n",
    "    except Exception as e:\n",
    "        return f'❌ Error al subir el padrón a GCP: {e}'\n",
    "\n",
    "def carga_share(share_data, project_id='gcp-ar-cdg-datos-dev', table_id='gcp-ar-cdg-datos-dev.marketshare_project.marketshare_data_test'):\n",
    "    try:\n",
    "        bq_methods = MethodBQ(project=project_id)\n",
    "        bq_methods.upsert_df_to_bigquery(\n",
    "            df=share_data,\n",
    "            table_id=table_id, \n",
    "            mode='append'\n",
    "        )\n",
    "\n",
    "        return 'Exito al cargar la informacion de Market Share a GCP'\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f'Hubo un error al intentar subir la nueva informacion de Share a GCP'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f250286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juan Mera\\Documents\\Python\\20_CARREFOUR\\progresion\\env\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Exito al cargar la informacion de Market Share a GCP'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carga_share(share_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d7fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ La tabla gcp-ar-cdg-datos-dev.marketshare_project.padron_test ya existe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juan Mera\\Documents\\Python\\20_CARREFOUR\\progresion\\env\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Éxito al cargar la información del padrón a GCP\n"
     ]
    }
   ],
   "source": [
    "print(carga_padron(padron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39de0e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juan Mera\\Documents\\Python\\20_CARREFOUR\\progresion\\env\\Lib\\site-packages\\bq_carrefour\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import bq_carrefour\n",
    "print(bq_carrefour.__file__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
