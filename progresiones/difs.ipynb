{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b8927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8180012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de Archivos y transformaciones generales\n",
    "cols_venta = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Grupo de Familia', 'Ventas c/impuesto', 'Venta en Unidades']\n",
    "df_ventas_y_volumen = pd.read_csv('data/ventas.csv', encoding='utf-16', header=1, usecols=cols_venta)\n",
    "\n",
    "cols_debitos = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Cant. Tickets por Local']\n",
    "df_debitos = pd.read_csv('data/debitos.csv', encoding='utf-16', header=1, sep=',', decimal=',', usecols=cols_debitos)\n",
    "\n",
    "cols_pad = ['GSX', 'NOMBRE', 'Fecha apertura', 'ORGANIZACIÓN ', 'M² SALÓN', 'M² PGC', 'M² PFT', 'M² BAZAR', 'M² Electro', 'M² Textil', 'M² Pls', 'M² GALERIAS', 'PROVINCIA', 'M² Parcking', 'FIN DE CIERRE', 'ENE.2', 'FEB.2', 'MAR.2', 'ABR.2', 'MAY.2', 'JUN.2', 'JUL.2', 'AGO.2', 'SEP.2', 'OCT.2', 'NOV.2', 'DIC.2']\n",
    "padron = pd.read_excel('data/padron.xlsx', header=17, usecols=cols_pad)\n",
    "\n",
    "#Renombro las columnas\n",
    "df_ventas_y_volumen.columns = (df_ventas_y_volumen.columns.str.strip().str.lower().str.replace(\" \", \"_\"))\n",
    "df_ventas_y_volumen = df_ventas_y_volumen.rename(columns={'ventas_c/impuesto':'venta', 'venta_en_unidades':'volumen'})\n",
    "\n",
    "#Genero una columna para Obtener el ID tienda\n",
    "df_ventas_y_volumen['numero_operacional'] = pd.to_numeric(df_ventas_y_volumen['punto_operacional'].str.split('-').str[0], errors='coerce')\n",
    "\n",
    "#Me quedo con las columnas necesarias\n",
    "ventas = df_ventas_y_volumen[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'grupo_de_familia', 'venta']]\n",
    "volumen = df_ventas_y_volumen[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'grupo_de_familia', 'volumen']]\n",
    "\n",
    "#Renombro las columnas con valores de ambos DF\n",
    "ventas = ventas.rename(columns={'venta':'valores'})\n",
    "volumen = volumen.rename(columns={'volumen':'valores'})\n",
    "\n",
    "#Realizo transformaciones para quitar carateres y convertir las columnas a valores numericos\n",
    "ventas['valores'] = pd.to_numeric(ventas['valores'].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "volumen['valores'] =pd.to_numeric(volumen['valores'].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "#Categorizo los valores tanto de volumne como de Ventas\n",
    "ventas['categoria'] = 'VCT'\n",
    "volumen['categoria'] = 'VOL'\n",
    "\n",
    "#Agrupo las ventas\n",
    "ventas_agrupado = ventas.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "#Quito Envases del Volumen y Agrupo\n",
    "volumen_sin_vol = volumen[~volumen['grupo_de_familia'].isin(['ENVASES PAGADOS', 'ENVASES BEBIDAS'])]\n",
    "#Si le quito las regularizadoras, el volumnes se me chinga todo!\n",
    "#volumen_sin_vol = volumen[~volumen['grupo_de_familia'].str.contains('REGULARIZADOR')]\n",
    "volumen_agrupado = volumen_sin_vol.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "# Trabajo sobre Debitos\n",
    "# Renombro el DF\n",
    "debitos_agrupados = df_debitos\n",
    "\n",
    "# Renombro las columnas como corresponden\n",
    "debitos_agrupados.columns = debitos_agrupados.columns.str.lower().str.replace(' ','_')\n",
    "debitos_agrupados = debitos_agrupados.rename(columns={'cant._tickets_por_local':'valores'})\n",
    "\n",
    "# Genero una columna Categorica\n",
    "debitos_agrupados['categoria'] = 'DEB'\n",
    "\n",
    "# Genero columna para el ID tienda\n",
    "debitos_agrupados['numero_operacional'] = pd.to_numeric(debitos_agrupados['punto_operacional'].str.split('-').str[0], errors='coerce')\n",
    "\n",
    "# Convierto la columna de valores a su tipo de datos correspondiente\n",
    "debitos_agrupados['valores'] = pd.to_numeric(debitos_agrupados['valores'].str.replace('.',''), errors='coerce')\n",
    "\n",
    "# Trabajo sobre el padron\n",
    "# Cambio de nombres en el padron\n",
    "padron.columns = (\n",
    "padron.columns\n",
    ".str.lower()\n",
    ".str.strip()\n",
    ".str.replace(' ', '_', regex=False)\n",
    ".str.replace('m²', 'm', regex=False)\n",
    ".str.replace('.2','')\n",
    ")\n",
    "\n",
    "# Formateo la fecha para que tenga sentido\n",
    "padron['fecha_apertura'] = padron['fecha_apertura'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Cambio el nombre de la columna N por \"Numero Operacional\"\n",
    "padron = padron.rename(columns={'gsx':'numero_operacional'})\n",
    "\n",
    "# Me aseguro que la columna de fin_de_cierre sea Datetime para realizar una columna auxiliar y quitar la tiendas que esten cerradas por mas de años que causan problemas de duplicados\n",
    "padron['fin_de_cierre'] = pd.to_datetime(padron['fin_de_cierre'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "#Me aseguro que la columna de Numero Operacional sea un numero \n",
    "padron['numero_operacional'] = pd.to_numeric(padron['numero_operacional'], errors='coerce')\n",
    "\n",
    "#Normalizo la columna de Direccion/Organización\n",
    "padron['organización'] = padron['organización'].str.lower()\n",
    "\n",
    "#Me quedo unicamente con los formatos fisicos\n",
    "padron = padron[padron['organización'].isin(['express', 'hipermercado', 'market', 'maxi'])]\n",
    "\n",
    "#Quito los duplicados del padron por numero operacional\n",
    "padron['numero_operacional'] = padron['numero_operacional'].drop_duplicates(keep='first')\n",
    "\n",
    "# Quito los valores nulos utilizando como referencia la columna Numero Operacional, nombre y fecha apertura\n",
    "padron = padron.dropna(subset=['numero_operacional', 'nombre', 'fecha_apertura'], how='any')\n",
    "\n",
    "#Genero una condicion vectorizada para calcular el tiempo que tienen cerradas las tiendas\n",
    "hoy = pd.Timestamp.today().normalize()\n",
    "\n",
    "dias_cierre = hoy - padron['fin_de_cierre']\n",
    "\n",
    "padron['vida'] = np.select(\n",
    "    condlist=[\n",
    "        padron['fin_de_cierre'].isna(),\n",
    "        dias_cierre > pd.Timedelta(days=1095),\n",
    "        dias_cierre > pd.Timedelta(days=730),\n",
    "        dias_cierre > pd.Timedelta(days=365),\n",
    "        dias_cierre <= pd.Timedelta(days=365),\n",
    "    ],\n",
    "    choicelist=[\n",
    "        pd.NaT,\n",
    "        'Tienda cerrada por más de tres años',\n",
    "        'Tienda cerrada por más de dos años',\n",
    "        'Tienda cerrada por más de un año',\n",
    "        'Tienda cerrada por menos de un año',\n",
    "    ],\n",
    "    default=pd.NaT\n",
    ")\n",
    "\n",
    "# Concateno todos los df (venta, debito y volumen) y lo joineo con el padron\n",
    "df = pd.concat([ventas_agrupado, volumen_agrupado, debitos_agrupados])\n",
    "\n",
    "#Normalizo columna\n",
    "df['direccion'] = df['direccion'].str.lower()\n",
    "\n",
    "# Me quedo con los formatos fisicos\n",
    "df = df[df['direccion'].isin(['proximidad', 'maxi', 'hipermercado', 'market'])]\n",
    "\n",
    "padron = padron.rename(columns={'organización':'direccion'})\n",
    "\n",
    "padron['direccion'] = np.where(padron['direccion'] == 'express', 'proximidad', padron['direccion'])\n",
    "\n",
    "# Genero el Join del df Agupado con el Padron con el objetivo de quedarme unicamente con aquellas tiendas Comparables\n",
    "df_join = pd.merge(left=df, right=padron, how='left', on=['numero_operacional', 'direccion'])\n",
    "\n",
    "#Renombro la columna de Comparabilidad para que tenga sentido\n",
    "df_join = df_join.rename(columns={mes_comparable[0:3].lower(): 'superficie'})\n",
    "\n",
    "# Me quedo unicamente con las columnas que me sirven del DF Joineado (ACA TENGO LA SC DEL MES)\n",
    "df_join = df_join[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'fecha_apertura', 'fin_de_cierre', 'm_salón', 'provincia','categoria', 'valores', 'superficie', 'vida']]\n",
    "\n",
    "#Renombro la Columna Mes a Fecha para Luego generar la Columna Mes Correspondiente\n",
    "df_join = df_join.rename(columns={'mes':'fecha'})\n",
    "\n",
    "#Genero columna de Mes\n",
    "df_join['mes'] = df_join['fecha'].str.split(' ').str[0]\n",
    "\n",
    "#Completo columna Vida\n",
    "df_join['vida'] = df_join['vida'].fillna('Tienda Abierta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_join_comparable(ventas, debitos, padron, mes_comparable:str): \n",
    "    try:\n",
    "        # Carga de Archivos y transformaciones generales\n",
    "        cols_venta = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Grupo de Familia', 'Ventas c/impuesto', 'Venta en Unidades']\n",
    "        df_ventas_y_volumen = pd.read_csv('data/ventas.csv', encoding='utf-16', header=1, usecols=cols_venta)\n",
    "\n",
    "        cols_debitos = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Cant. Tickets por Local']\n",
    "        df_debitos = pd.read_csv('data/debitos.csv', encoding='utf-16', header=1, sep=',', decimal=',', usecols=cols_debitos)\n",
    "\n",
    "        cols_pad = ['GSX', 'NOMBRE', 'Fecha apertura', 'ORGANIZACIÓN ', 'M² SALÓN', 'M² PGC', 'M² PFT', 'M² BAZAR', 'M² Electro', 'M² Textil', 'M² Pls', 'M² GALERIAS', 'PROVINCIA', 'M² Parcking', 'FIN DE CIERRE', 'ENE.2', 'FEB.2', 'MAR.2', 'ABR.2', 'MAY.2', 'JUN.2', 'JUL.2', 'AGO.2', 'SEP.2', 'OCT.2', 'NOV.2', 'DIC.2']\n",
    "        padron = pd.read_excel('data/padron.xlsx', header=17, usecols=cols_pad)\n",
    "\n",
    "        #Renombro las columnas\n",
    "        df_ventas_y_volumen.columns = (df_ventas_y_volumen.columns.str.strip().str.lower().str.replace(\" \", \"_\"))\n",
    "        df_ventas_y_volumen = df_ventas_y_volumen.rename(columns={'ventas_c/impuesto':'venta', 'venta_en_unidades':'volumen'})\n",
    "\n",
    "        #Genero una columna para Obtener el ID tienda\n",
    "        df_ventas_y_volumen['numero_operacional'] = pd.to_numeric(df_ventas_y_volumen['punto_operacional'].str.split('-').str[0], errors='coerce')\n",
    "\n",
    "        #Me quedo con las columnas necesarias\n",
    "        ventas = df_ventas_y_volumen[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'grupo_de_familia', 'venta']]\n",
    "        volumen = df_ventas_y_volumen[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'grupo_de_familia', 'volumen']]\n",
    "\n",
    "        #Renombro las columnas con valores de ambos DF\n",
    "        ventas = ventas.rename(columns={'venta':'valores'})\n",
    "        volumen = volumen.rename(columns={'volumen':'valores'})\n",
    "\n",
    "        #Realizo transformaciones para quitar carateres y convertir las columnas a valores numericos\n",
    "        ventas['valores'] = pd.to_numeric(ventas['valores'].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "        volumen['valores'] =pd.to_numeric(volumen['valores'].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        #Categorizo los valores tanto de volumne como de Ventas\n",
    "        ventas['categoria'] = 'VCT'\n",
    "        volumen['categoria'] = 'VOL'\n",
    "\n",
    "        #Agrupo las ventas\n",
    "        ventas_agrupado = ventas.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "        #Quito Envases del Volumen y Agrupo\n",
    "        volumen_sin_vol = volumen[~volumen['grupo_de_familia'].isin(['ENVASES PAGADOS', 'ENVASES BEBIDAS'])]\n",
    "        #Si le quito las regularizadoras, el volumnes se me chinga todo!\n",
    "        #volumen_sin_vol = volumen[~volumen['grupo_de_familia'].str.contains('REGULARIZADOR')]\n",
    "        volumen_agrupado = volumen_sin_vol.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "        # Trabajo sobre Debitos\n",
    "        # Renombro el DF\n",
    "        debitos_agrupados = df_debitos\n",
    "\n",
    "        # Renombro las columnas como corresponden\n",
    "        debitos_agrupados.columns = debitos_agrupados.columns.str.lower().str.replace(' ','_')\n",
    "        debitos_agrupados = debitos_agrupados.rename(columns={'cant._tickets_por_local':'valores'})\n",
    "\n",
    "        # Genero una columna Categorica\n",
    "        debitos_agrupados['categoria'] = 'DEB'\n",
    "\n",
    "        # Genero columna para el ID tienda\n",
    "        debitos_agrupados['numero_operacional'] = pd.to_numeric(debitos_agrupados['punto_operacional'].str.split('-').str[0], errors='coerce')\n",
    "\n",
    "        # Convierto la columna de valores a su tipo de datos correspondiente\n",
    "        debitos_agrupados['valores'] = pd.to_numeric(debitos_agrupados['valores'].str.replace('.',''), errors='coerce')\n",
    "\n",
    "        # Trabajo sobre el padron\n",
    "        # Cambio de nombres en el padron\n",
    "        padron.columns = (\n",
    "        padron.columns\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace('m²', 'm', regex=False)\n",
    "        .str.replace('.2','')\n",
    "        )\n",
    "\n",
    "        # Formateo la fecha para que tenga sentido\n",
    "        padron['fecha_apertura'] = padron['fecha_apertura'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "        # Cambio el nombre de la columna N por \"Numero Operacional\"\n",
    "        padron = padron.rename(columns={'gsx':'numero_operacional'})\n",
    "\n",
    "        # Me aseguro que la columna de fin_de_cierre sea Datetime para realizar una columna auxiliar y quitar la tiendas que esten cerradas por mas de años que causan problemas de duplicados\n",
    "        padron['fin_de_cierre'] = pd.to_datetime(padron['fin_de_cierre'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "        #Me aseguro que la columna de Numero Operacional sea un numero \n",
    "        padron['numero_operacional'] = pd.to_numeric(padron['numero_operacional'], errors='coerce')\n",
    "\n",
    "        #Normalizo la columna de Direccion/Organización\n",
    "        padron['organización'] = padron['organización'].str.lower()\n",
    "\n",
    "        #Me quedo unicamente con los formatos fisicos\n",
    "        padron = padron[padron['organización'].isin(['express', 'hipermercado', 'market', 'maxi'])]\n",
    "\n",
    "        #Quito los duplicados del padron por numero operacional\n",
    "        padron['numero_operacional'] = padron['numero_operacional'].drop_duplicates(keep='first')\n",
    "\n",
    "        # Quito los valores nulos utilizando como referencia la columna Numero Operacional, nombre y fecha apertura\n",
    "        padron = padron.dropna(subset=['numero_operacional', 'nombre', 'fecha_apertura'], how='any')\n",
    "\n",
    "        #Genero una condicion vectorizada para calcular el tiempo que tienen cerradas las tiendas\n",
    "        hoy = pd.Timestamp.today().normalize()\n",
    "\n",
    "        dias_cierre = hoy - padron['fin_de_cierre']\n",
    "\n",
    "        padron['vida'] = np.select(\n",
    "            condlist=[\n",
    "                padron['fin_de_cierre'].isna(),\n",
    "                dias_cierre > pd.Timedelta(days=1095),\n",
    "                dias_cierre > pd.Timedelta(days=730),\n",
    "                dias_cierre > pd.Timedelta(days=365),\n",
    "                dias_cierre <= pd.Timedelta(days=365),\n",
    "            ],\n",
    "            choicelist=[\n",
    "                pd.NaT,\n",
    "                'Tienda cerrada por más de tres años',\n",
    "                'Tienda cerrada por más de dos años',\n",
    "                'Tienda cerrada por más de un año',\n",
    "                'Tienda cerrada por menos de un año',\n",
    "            ],\n",
    "            default=pd.NaT\n",
    "        )\n",
    "\n",
    "        # Concateno todos los df (venta, debito y volumen) y lo joineo con el padron\n",
    "        df = pd.concat([ventas_agrupado, volumen_agrupado, debitos_agrupados])\n",
    "\n",
    "        #Normalizo columna\n",
    "        df['direccion'] = df['direccion'].str.lower()\n",
    "\n",
    "        # Me quedo con los formatos fisicos\n",
    "        df = df[df['direccion'].isin(['proximidad', 'maxi', 'hipermercado', 'market'])]\n",
    "\n",
    "        padron = padron.rename(columns={'organización':'direccion'})\n",
    "\n",
    "        padron['direccion'] = np.where(padron['direccion'] == 'express', 'proximidad', padron['direccion'])\n",
    "\n",
    "        # Genero el Join del df Agupado con el Padron con el objetivo de quedarme unicamente con aquellas tiendas Comparables\n",
    "        df_join = pd.merge(left=df, right=padron, how='left', on=['numero_operacional', 'direccion'])\n",
    "\n",
    "        #Renombro la columna de Comparabilidad para que tenga sentido\n",
    "        df_join = df_join.rename(columns={mes_comparable[0:3].lower(): 'superficie'})\n",
    "\n",
    "        # Me quedo unicamente con las columnas que me sirven del DF Joineado (ACA TENGO LA SC DEL MES)\n",
    "        df_join = df_join[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'fecha_apertura', 'fin_de_cierre', 'm_salón', 'provincia','categoria', 'valores', 'superficie', 'vida']]\n",
    "\n",
    "        #Renombro la Columna Mes a Fecha para Luego generar la Columna Mes Correspondiente\n",
    "        df_join = df_join.rename(columns={'mes':'fecha'})\n",
    "\n",
    "        #Genero columna de Mes\n",
    "        df_join['mes'] = df_join['fecha'].str.split(' ').str[0]\n",
    "\n",
    "        #Completo columna Vida\n",
    "        df_join['vida'] = df_join['vida'].fillna('Tienda Abierta')\n",
    "        \n",
    "        df_join_sc = df_join[df_join['superficie'] == 'SC']\n",
    "\n",
    "        try:\n",
    "            output = io.BytesIO()\n",
    "            df_join_sc.to_csv(output, index=False, encoding=\"utf-16\", decimal=',')\n",
    "            \n",
    "            output.seek(0)\n",
    "            return output\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        return f'Hubo un error en el medio del flujo/pipeline. Detalle del error: {e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_join_no_comparable(ventas, debitos, padron, mes_comparable:str): \n",
    "    try:\n",
    "        # Carga de Archivos y transformaciones generales\n",
    "        cols_venta = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Grupo de Familia', 'Ventas c/impuesto', 'Venta en Unidades']\n",
    "        df_ventas_y_volumen = pd.read_csv('data/ventas.csv', encoding='utf-16', header=1, usecols=cols_venta)\n",
    "\n",
    "        cols_debitos = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Cant. Tickets por Local']\n",
    "        df_debitos = pd.read_csv('data/debitos.csv', encoding='utf-16', header=1, sep=',', decimal=',', usecols=cols_debitos)\n",
    "\n",
    "        cols_pad = ['GSX', 'NOMBRE', 'Fecha apertura', 'ORGANIZACIÓN ', 'M² SALÓN', 'M² PGC', 'M² PFT', 'M² BAZAR', 'M² Electro', 'M² Textil', 'M² Pls', 'M² GALERIAS', 'PROVINCIA', 'M² Parcking', 'FIN DE CIERRE', 'ENE.2', 'FEB.2', 'MAR.2', 'ABR.2', 'MAY.2', 'JUN.2', 'JUL.2', 'AGO.2', 'SEP.2', 'OCT.2', 'NOV.2', 'DIC.2']\n",
    "        padron = pd.read_excel('data/padron.xlsx', header=17, usecols=cols_pad)\n",
    "\n",
    "        #Renombro las columnas\n",
    "        df_ventas_y_volumen.columns = (df_ventas_y_volumen.columns.str.strip().str.lower().str.replace(\" \", \"_\"))\n",
    "        df_ventas_y_volumen = df_ventas_y_volumen.rename(columns={'ventas_c/impuesto':'venta', 'venta_en_unidades':'volumen'})\n",
    "\n",
    "        #Genero una columna para Obtener el ID tienda\n",
    "        df_ventas_y_volumen['numero_operacional'] = pd.to_numeric(df_ventas_y_volumen['punto_operacional'].str.split('-').str[0], errors='coerce')\n",
    "\n",
    "        #Me quedo con las columnas necesarias\n",
    "        ventas = df_ventas_y_volumen[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'grupo_de_familia', 'venta']]\n",
    "        volumen = df_ventas_y_volumen[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'grupo_de_familia', 'volumen']]\n",
    "\n",
    "        #Renombro las columnas con valores de ambos DF\n",
    "        ventas = ventas.rename(columns={'venta':'valores'})\n",
    "        volumen = volumen.rename(columns={'volumen':'valores'})\n",
    "\n",
    "        #Realizo transformaciones para quitar carateres y convertir las columnas a valores numericos\n",
    "        ventas['valores'] = pd.to_numeric(ventas['valores'].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "        volumen['valores'] =pd.to_numeric(volumen['valores'].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "        #Categorizo los valores tanto de volumne como de Ventas\n",
    "        ventas['categoria'] = 'VCT'\n",
    "        volumen['categoria'] = 'VOL'\n",
    "\n",
    "        #Agrupo las ventas\n",
    "        ventas_agrupado = ventas.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "        #Quito Envases del Volumen y Agrupo\n",
    "        volumen_sin_vol = volumen[~volumen['grupo_de_familia'].isin(['ENVASES PAGADOS', 'ENVASES BEBIDAS'])]\n",
    "        #Si le quito las regularizadoras, el volumnes se me chinga todo!\n",
    "        #volumen_sin_vol = volumen[~volumen['grupo_de_familia'].str.contains('REGULARIZADOR')]\n",
    "        volumen_agrupado = volumen_sin_vol.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "        # Trabajo sobre Debitos\n",
    "        # Renombro el DF\n",
    "        debitos_agrupados = df_debitos\n",
    "\n",
    "        # Renombro las columnas como corresponden\n",
    "        debitos_agrupados.columns = debitos_agrupados.columns.str.lower().str.replace(' ','_')\n",
    "        debitos_agrupados = debitos_agrupados.rename(columns={'cant._tickets_por_local':'valores'})\n",
    "\n",
    "        # Genero una columna Categorica\n",
    "        debitos_agrupados['categoria'] = 'DEB'\n",
    "\n",
    "        # Genero columna para el ID tienda\n",
    "        debitos_agrupados['numero_operacional'] = pd.to_numeric(debitos_agrupados['punto_operacional'].str.split('-').str[0], errors='coerce')\n",
    "\n",
    "        # Convierto la columna de valores a su tipo de datos correspondiente\n",
    "        debitos_agrupados['valores'] = pd.to_numeric(debitos_agrupados['valores'].str.replace('.',''), errors='coerce')\n",
    "\n",
    "        # Trabajo sobre el padron\n",
    "        # Cambio de nombres en el padron\n",
    "        padron.columns = (\n",
    "        padron.columns\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace('m²', 'm', regex=False)\n",
    "        .str.replace('.2','')\n",
    "        )\n",
    "\n",
    "        # Formateo la fecha para que tenga sentido\n",
    "        padron['fecha_apertura'] = padron['fecha_apertura'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "        # Cambio el nombre de la columna N por \"Numero Operacional\"\n",
    "        padron = padron.rename(columns={'gsx':'numero_operacional'})\n",
    "\n",
    "        # Me aseguro que la columna de fin_de_cierre sea Datetime para realizar una columna auxiliar y quitar la tiendas que esten cerradas por mas de años que causan problemas de duplicados\n",
    "        padron['fin_de_cierre'] = pd.to_datetime(padron['fin_de_cierre'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "        #Me aseguro que la columna de Numero Operacional sea un numero \n",
    "        padron['numero_operacional'] = pd.to_numeric(padron['numero_operacional'], errors='coerce')\n",
    "\n",
    "        #Normalizo la columna de Direccion/Organización\n",
    "        padron['organización'] = padron['organización'].str.lower()\n",
    "\n",
    "        #Me quedo unicamente con los formatos fisicos\n",
    "        padron = padron[padron['organización'].isin(['express', 'hipermercado', 'market', 'maxi'])]\n",
    "\n",
    "        #Quito los duplicados del padron por numero operacional\n",
    "        padron['numero_operacional'] = padron['numero_operacional'].drop_duplicates(keep='first')\n",
    "\n",
    "        # Quito los valores nulos utilizando como referencia la columna Numero Operacional, nombre y fecha apertura\n",
    "        padron = padron.dropna(subset=['numero_operacional', 'nombre', 'fecha_apertura'], how='any')\n",
    "\n",
    "        #Genero una condicion vectorizada para calcular el tiempo que tienen cerradas las tiendas\n",
    "        hoy = pd.Timestamp.today().normalize()\n",
    "\n",
    "        dias_cierre = hoy - padron['fin_de_cierre']\n",
    "\n",
    "        padron['vida'] = np.select(\n",
    "            condlist=[\n",
    "                padron['fin_de_cierre'].isna(),\n",
    "                dias_cierre > pd.Timedelta(days=1095),\n",
    "                dias_cierre > pd.Timedelta(days=730),\n",
    "                dias_cierre > pd.Timedelta(days=365),\n",
    "                dias_cierre <= pd.Timedelta(days=365),\n",
    "            ],\n",
    "            choicelist=[\n",
    "                pd.NaT,\n",
    "                'Tienda cerrada por más de tres años',\n",
    "                'Tienda cerrada por más de dos años',\n",
    "                'Tienda cerrada por más de un año',\n",
    "                'Tienda cerrada por menos de un año',\n",
    "            ],\n",
    "            default=pd.NaT\n",
    "        )\n",
    "\n",
    "        # Concateno todos los df (venta, debito y volumen) y lo joineo con el padron\n",
    "        df = pd.concat([ventas_agrupado, volumen_agrupado, debitos_agrupados])\n",
    "\n",
    "        #Normalizo columna\n",
    "        df['direccion'] = df['direccion'].str.lower()\n",
    "\n",
    "        # Me quedo con los formatos fisicos\n",
    "        df = df[df['direccion'].isin(['proximidad', 'maxi', 'hipermercado', 'market'])]\n",
    "\n",
    "        padron = padron.rename(columns={'organización':'direccion'})\n",
    "\n",
    "        padron['direccion'] = np.where(padron['direccion'] == 'express', 'proximidad', padron['direccion'])\n",
    "\n",
    "        # Genero el Join del df Agupado con el Padron con el objetivo de quedarme unicamente con aquellas tiendas Comparables\n",
    "        df_join = pd.merge(left=df, right=padron, how='left', on=['numero_operacional', 'direccion'])\n",
    "\n",
    "        #Renombro la columna de Comparabilidad para que tenga sentido\n",
    "        df_join = df_join.rename(columns={mes_comparable[0:3].lower(): 'superficie'})\n",
    "\n",
    "        # Me quedo unicamente con las columnas que me sirven del DF Joineado (ACA TENGO LA SC DEL MES)\n",
    "        df_join = df_join[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'fecha_apertura', 'fin_de_cierre', 'm_salón', 'provincia','categoria', 'valores', 'superficie', 'vida']]\n",
    "\n",
    "        #Renombro la Columna Mes a Fecha para Luego generar la Columna Mes Correspondiente\n",
    "        df_join = df_join.rename(columns={'mes':'fecha'})\n",
    "\n",
    "        #Genero columna de Mes\n",
    "        df_join['mes'] = df_join['fecha'].str.split(' ').str[0]\n",
    "\n",
    "        #Completo columna Vida\n",
    "        df_join['vida'] = df_join['vida'].fillna('Tienda Abierta')\n",
    "\n",
    "        try:\n",
    "            output = io.BytesIO()\n",
    "            df_join_sc.to_csv(output, index=False, encoding=\"utf-16\", decimal=',')\n",
    "            \n",
    "            output.seek(0)\n",
    "            return output\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        return f'Hubo un error en el medio del flujo/pipeline. Detalle del error: {e}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7669616",
   "metadata": {},
   "source": [
    "# AUXI BRIEFINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45943e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012ec92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_comparable = 'Diciembre'\n",
    "try:\n",
    "    cols = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Sector', 'Seccion', 'Grupo de Familia', 'Ventas c/impuesto', 'Venta en Unidades']\n",
    "    df_ventas_vol = pd.read_csv('data/2026/ventas Dic - Primer Semana Briefing.csv', encoding='utf-16', header=1, usecols=cols, decimal=',')\n",
    "except Exception as e:\n",
    "    print(f'Error a la hora de cargar las Ventas y el Volumen. ERROR: {e}')\n",
    "\n",
    "# Trabajo sobre los Debitos TOTALES por Tienda\n",
    "# Cargo el archivo CSV\n",
    "try:\n",
    "    df_debitos_tienda = pd.read_csv('data/2026/debitos Dic - Primer Semana briefing.csv', encoding='utf-16', header=1, decimal=',')\n",
    "except Exception as e:\n",
    "    print(f'Error a la hora de cargar los Debitos. ERROR: {e}')\n",
    "\n",
    "# Leo el Padron\n",
    "try:\n",
    "    # Cargo y trabajo sobre el PADRON\n",
    "    # Cargo unicamente las columnas que me van a servir\n",
    "    pad_cols = ['GSX', 'NOMBRE', 'Fecha apertura', 'BANDERA', 'ORGANIZACIÓN ', 'PROVINCIA', 'FIN DE CIERRE', 'ENE.2', 'FEB.2', 'MAR.2', 'ABR.2', 'MAY.2', 'JUN.2', 'JUL.2', 'AGO.2', 'SEP.2', 'OCT.2', 'NOV.2', 'DIC.2']\n",
    "    padron = pd.read_excel('data/2026/padron dic 2025.xlsx', header=17, usecols=pad_cols)\n",
    "except Exception as e:\n",
    "    print(f'Error a la hora de cargar el Padron. ERROR: {e}')\n",
    "\n",
    "# Estandarizo el nombre de las columnas\n",
    "df_ventas_vol.columns = df_ventas_vol.columns.str.lower().str.replace(' ','_')\n",
    "\n",
    "# Estandarizo el nombre de las columnas\n",
    "df_ventas_vol.columns = df_ventas_vol.columns.str.lower().str.replace(' ','_')\n",
    "\n",
    "# Renombro columnas para que tenga mas sentido\n",
    "df_ventas_vol = df_ventas_vol.rename(columns=\n",
    "    {\n",
    "        'mes':'fecha',\n",
    "        'ventas_c/impuesto':'vct',\n",
    "        'venta_en_unidades':'vol'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Genero una columna para obtener el valor del MES solo\n",
    "df_ventas_vol['mes'] = df_ventas_vol['fecha'].str.split(' ').str[0]\n",
    "\n",
    "# Genero una columna para obtener el NUMERO operacional de la tienda y lo convierto a numero\n",
    "df_ventas_vol['numero_operacional'] = df_ventas_vol['punto_operacional'].str.split(' ').str[0].astype(int)\n",
    "\n",
    "# Divido el df de Ventas y Volumen en uno solo de Ventas, y otro solo de Volumen!\n",
    "df_ventas = df_ventas_vol[['año', 'fecha', 'direccion', 'punto_operacional', 'sector', 'seccion', 'grupo_de_familia', 'vct', 'mes', 'numero_operacional']]\n",
    "df_volumen = df_ventas_vol[['año', 'fecha', 'direccion', 'punto_operacional', 'sector', 'seccion', 'grupo_de_familia', 'vol', 'mes', 'numero_operacional']]\n",
    "\n",
    "# Renombro la columna donde se encuentran los valores a \"valores\". Esto me servirá luego para realizar un concat\n",
    "df_ventas = df_ventas.rename(columns={'vct':'valores'})\n",
    "df_volumen = df_volumen.rename(columns={'vol':'valores'})\n",
    "\n",
    "# Genero una columna categorica para distinguir cuales son los valores de las ventas , y cuales son los valores del volumen\n",
    "df_ventas['categoria'] = 'vct'\n",
    "df_volumen['categoria'] = 'vol'\n",
    "\n",
    "# Genero una transformacion en la columna valores para obtener un dtype correspondiente, ya que al leer los archivos, la columna valores queda como un string y no detecta de forma correcta los puntos y las comas\n",
    "df_ventas['valores'] = pd.to_numeric(df_ventas['valores'].str.replace('.', '').str.replace(',','.'))\n",
    "df_volumen['valores'] = pd.to_numeric(df_volumen['valores'].str.replace('.', '').str.replace(',','.'))\n",
    "\n",
    "# Le quito los envases al volumen\n",
    "df_volumen = df_volumen[~df_volumen['grupo_de_familia'].isin(['ENVASES BEBIDAS', 'ENVASES PAGADOS'])]\n",
    "\n",
    "# Una vez que ambos df estan limpios y ordenados, los agrupo para elevar su jerarquia hasta la tienda, ya que el sector, seccion y grupo de familia no son necesarios para calular las progresiones POR TIENDA\n",
    "df_ventas_tienda = df_ventas.groupby(['año', 'mes', 'fecha', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "df_volumen_tienda = df_volumen.groupby(['año', 'mes', 'fecha','direccion', 'numero_operacional', 'punto_operacional', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "# Estandarizo los nombres de las columnas del padron\n",
    "padron.columns = padron.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('.2', '')\n",
    "\n",
    "meses_dict = {\n",
    "'enero': 'ene',\n",
    "'febrero': 'feb',\n",
    "'marzo': 'mar',\n",
    "'abril': 'abr',\n",
    "'mayo': 'may',\n",
    "'junio': 'jun',\n",
    "'julio': 'jul',\n",
    "'agosto': 'ago',\n",
    "'septiembre': 'sep',\n",
    "'octubre': 'oct',\n",
    "'noviembre': 'nov',\n",
    "'diciembre': 'dic'\n",
    "}\n",
    "\n",
    "columna_mes = meses_dict.get(mes_comparable.lower())\n",
    "if not columna_mes:\n",
    "    raise ValueError(f\"Mes '{mes_comparable}' no reconocido. Usá un nombre completo (por ejemplo: 'Octubre').\")\n",
    "\n",
    "# Renombro algunas columnas para que tengan mas sentido\n",
    "padron = padron.rename(columns={'gsx':'numero_operacional'})\n",
    "\n",
    "# Elimino las filas que tengan NA en su numero, nombre o mes comparable\n",
    "padron = padron.dropna(subset=['numero_operacional', 'nombre', columna_mes], how='any')\n",
    "\n",
    "# Convierto la columna de Numero Operacional efectivamente a INT\n",
    "padron['numero_operacional'] = padron['numero_operacional'].astype(int)\n",
    "\n",
    "# Estandarizo las columnas\n",
    "df_debitos_tienda.columns = df_debitos_tienda.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Renombro columnas para que tengan mas sentido\n",
    "df_debitos_tienda =df_debitos_tienda.rename(columns=\n",
    "    {\n",
    "    'cant._tickets_por_local':'valores',\n",
    "    'mes':'fecha',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convierto la columna de valores a numero\n",
    "df_debitos_tienda['valores'] = pd.to_numeric(df_debitos_tienda['valores'].str.replace('.', '').str.replace(',','.'))\n",
    "\n",
    "# Genero una columna de MES\n",
    "df_debitos_tienda['mes'] = df_debitos_tienda['fecha'].str.split(' ').str[0]\n",
    "\n",
    "# Genero una columna para obtener el Numero de Tienda y convertirlo a INT\n",
    "df_debitos_tienda['numero_operacional'] = df_debitos_tienda['punto_operacional'].str.split(' ').str[0].astype(int)\n",
    "\n",
    "# Elimino las columnas que no me sirven\n",
    "df_debitos_tienda = df_debitos_tienda.drop(columns=['indicadores'])\n",
    "\n",
    "# Genero una columna categorica para distinguir los debitos una vez que realice un concat con el volumen y las ventas\n",
    "df_debitos_tienda['categoria'] = 'deb'\n",
    "\n",
    "# Ordeno el df de la misma forma que el de Ventas y volumen para realizar un concat de los debitos, venta y volumen a nivel tienda\n",
    "df_debitos_tienda = df_debitos_tienda[['año', 'mes', 'fecha', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'valores']]\n",
    "\n",
    "# Concateno todo a NIVEL TIENDA y Realizo un Join con el Padron\n",
    "df_tienda = pd.concat([df_ventas_tienda, df_debitos_tienda, df_volumen_tienda])\n",
    "df_tienda['numero_operacional'] = df_tienda['numero_operacional'].astype(int)\n",
    "\n",
    "# Realizo el Join con el Padron\n",
    "df_tienda_join = pd.merge(df_tienda, padron, how='left', on='numero_operacional')\n",
    "\n",
    "# Selecciono las columnas que me quiero quedar para trabajar mas comodo\n",
    "df_tienda_join = df_tienda_join[['año', 'mes', 'fecha', 'direccion', 'numero_operacional', 'punto_operacional', 'provincia', 'fecha_apertura', 'fin_de_cierre','categoria', columna_mes, 'valores']]\n",
    "meses_aux = {\n",
    "    'Enero': '01',\n",
    "    'Febrero': '02',\n",
    "    'Marzo': '03',\n",
    "    'Abril': '04',\n",
    "    'Mayo': '05',\n",
    "    'Junio': '06',\n",
    "    'Julio': '07',\n",
    "    'Agosto': '08',\n",
    "    'Septiembre': '09',\n",
    "    'Octubre': '10',\n",
    "    'Noviembre': '11',\n",
    "    'Diciembre': '12'\n",
    "}\n",
    "\n",
    "df_tienda_join['mes_num'] = df_tienda_join['mes'].map(meses_aux)\n",
    "df_tienda_join['pivot'] = pd.to_datetime('01/' + df_tienda_join['mes_num'].astype(str) + '/' + df_tienda_join['año'].astype(str), format='%d/%m/%Y')\n",
    "fecha_de_corte = datetime.today() - timedelta(days=(365/2))\n",
    "df_tienda_join['periodo'] = np.where(df_tienda_join['pivot'] > fecha_de_corte, 'periodo nuevo', 'periodo viejo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5e880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro el df unicamente por aquellos valores con SUPERFICIE COMPARABLE\n",
    "df_tienda_comparable = df_tienda_join[df_tienda_join[columna_mes] == 'SC']\n",
    "\n",
    "# Genero una copia del df con TODOS LOS VALORES para obtener sus progresiones tambien por Superficie TOTAL. Esto es util para el briefing de Maxi ya que tiene graficos a nivel total y por sup comparable\n",
    "df_tienda_no_comparable = df_tienda_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5e8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoteo la Informacion con el objetivo de llevar los valores por Año a las columnas y asi realizar el calculo de progresiones. Esto lo hago tanto para el df con valores comparables y valores total. EN ESTE PASO ESTOY CALCULANDO LAS PROGRESIONES POR TIENDA\n",
    "df_tienda_comparable = df_tienda_comparable.pivot_table(values='valores', index=['direccion', 'numero_operacional', 'punto_operacional', 'categoria'], columns=['periodo'], aggfunc='sum').reset_index()\n",
    "df_tienda_comparable['progresion'] = round((df_tienda_comparable['periodo nuevo'] / df_tienda_comparable['periodo viejo']) - 1, 3)\n",
    "df_tienda_comparable = df_tienda_comparable.sort_values(by='progresion', ascending=False)\n",
    "\n",
    "df_tienda_no_comparable = df_tienda_no_comparable.pivot_table(values='valores', index=['direccion', 'numero_operacional', 'punto_operacional', 'categoria'], columns='periodo', aggfunc='sum').reset_index()\n",
    "df_tienda_no_comparable['progresion'] = round((df_tienda_no_comparable['periodo nuevo'] / df_tienda_no_comparable['periodo viejo']) - 1, 3)\n",
    "df_tienda_no_comparable = df_tienda_no_comparable.sort_values(by='progresion', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cef0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero un DF Auxiliar en este punto para luego concatenarlo con otros y asi tener una bajada consolidada de toda la informacion utilizada con el objetivo proximo re realizar un giratorio en Excel\n",
    "df_tienda_comparable_aux = df_tienda_comparable\n",
    "\n",
    "# Pivoteo la Informacion con el objetivo de llevar los valores por Año a las columnas y asi realizar el calculo de progresiones. Esto lo hago tanto para el df con valores comparables y valores total. EN ESTE PASO ESTOY CALCULANDO LAS PROGRESIONES POR FORMATO\n",
    "df_formato_comparable = df_tienda_comparable.groupby(['direccion', 'categoria'])[['periodo viejo', 'periodo nuevo']].sum().reset_index()\n",
    "df_formato_comparable['progresion'] = round(df_formato_comparable['periodo nuevo'] / df_formato_comparable['periodo viejo'] - 1, 3)\n",
    "df_formato_comparable_final = df_formato_comparable.sort_values(['categoria'])\n",
    "\n",
    "df_formato_no_comparable = df_tienda_no_comparable.groupby(['direccion', 'categoria'])[['periodo viejo', 'periodo nuevo']].sum().reset_index()\n",
    "df_formato_no_comparable['progresion'] = round(df_formato_no_comparable['periodo nuevo'] / df_formato_no_comparable['periodo viejo'] - 1, 3)\n",
    "df_formato_no_comparable_final = df_formato_no_comparable.sort_values(['categoria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a7a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan_mera\\AppData\\Local\\Temp\\ipykernel_6640\\1743466948.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sector_comparable['mes_num'] = df_sector_comparable['mes'].map(meses_aux)\n",
      "C:\\Users\\juan_mera\\AppData\\Local\\Temp\\ipykernel_6640\\1743466948.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sector_comparable['pivot'] = pd.to_datetime('01/' + df_sector_comparable['mes_num'].astype(str) + '/' + df_sector_comparable['año'].astype(str), format='%d/%m/%Y')\n",
      "C:\\Users\\juan_mera\\AppData\\Local\\Temp\\ipykernel_6640\\1743466948.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sector_comparable['periodo'] = np.where(df_sector_comparable['pivot'] > fecha_de_corte, 'periodo nuevo', 'periodo viejo')\n"
     ]
    }
   ],
   "source": [
    "# Una vez que ya tengo calculadas las progresiones por Formato y por Tienda, me falta calcular las progresiones por TIENDA y SECTOR. Ya que en el briefing la forma de mostrar las progresiones en principio es por Tienda y Formato, y luego se le coloca la progresion TOTAL de la tienda a la derecha de todo.\n",
    "\n",
    "# Comienzo por Importar los Debitos por Sector\n",
    "try:\n",
    "    df_debitos_sector = pd.read_csv('data/2026/debitos x sector Dic - Primer Semana Briefing.csv', encoding='utf-16', header=1, decimal=',')\n",
    "except Exception as e:\n",
    "    print(f'Error a la hora de cargar los Debitos por Sector. ERROR: {e}')\n",
    "\n",
    "# Realizo las mismas transformaciones para los otros df, pero esta vez, para los debitos por sector\n",
    "df_debitos_sector.columns = df_debitos_sector.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df_debitos_sector = df_debitos_sector.rename(columns=\n",
    "    {\n",
    "    'cantidad_de_tickets':'valores',\n",
    "    'mes':'fecha'\n",
    "    }\n",
    ")\n",
    "\n",
    "df_debitos_sector = df_debitos_sector.drop(columns=['indicadores'])\n",
    "df_debitos_sector['mes'] = df_debitos_sector['fecha'].str.split(' ').str[0]\n",
    "df_debitos_sector['numero_operacional'] = df_debitos_sector['punto_operacional'].str.split(' ').str[0]\n",
    "df_debitos_sector['categoria'] = 'deb'\n",
    "df_debitos_sector['valores'] = pd.to_numeric(df_debitos_sector['valores'].str.replace('.', '').str.replace(',','.'))\n",
    "\n",
    "# Una vez que ya tengo los Debitos por Sector limpio y ordenado, me aseguro de agrupar el volumen sin envases y las ventas de igual forma, POR SECTOR\n",
    "df_ventas_sector = df_ventas.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'sector'])['valores'].sum().reset_index()\n",
    "df_volumen_sector = df_volumen.groupby(['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'sector'])['valores'].sum().reset_index()\n",
    "df_debitos_sector = df_debitos_sector[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'sector', 'valores']]\n",
    "\n",
    "# En este punto ya puedo concatenar los tres df y asi obtener uno solo consolidado para trabajar mas comodo\n",
    "df_sector = pd.concat([df_ventas_sector, df_volumen_sector, df_debitos_sector])\n",
    "df_sector['numero_operacional'] = df_sector['numero_operacional'].astype(int)\n",
    "\n",
    "# Realizo un Join con el Padron y asi poder Filtrar los valores comparables, ya que los calculos de las progresiones por SECTOR son SIEMPRE COMPARABLES\n",
    "df_sector_join = pd.merge(df_sector, padron, on='numero_operacional', how='left')\n",
    "df_sector_join = df_sector_join[['año', 'mes', 'direccion', 'numero_operacional', 'punto_operacional', 'provincia', 'fecha_apertura', 'fin_de_cierre', 'categoria', 'sector', columna_mes, 'valores']]\n",
    "\n",
    "# Obtengo las superficies comparables\n",
    "df_sector_comparable = df_sector_join[df_sector_join[columna_mes] == 'SC']\n",
    "\n",
    "# Genero una columna auxiliar del numero de mes\n",
    "df_sector_comparable['mes_num'] = df_sector_comparable['mes'].map(meses_aux)\n",
    "\n",
    "# Genero una columna de fecha datetime\n",
    "df_sector_comparable['pivot'] = pd.to_datetime('01/' + df_sector_comparable['mes_num'].astype(str) + '/' + df_sector_comparable['año'].astype(str), format='%d/%m/%Y')\n",
    "\n",
    "# Utilizo la columna datetime para categorizar las fechas por periodo\n",
    "df_sector_comparable['periodo'] = np.where(df_sector_comparable['pivot'] > fecha_de_corte, 'periodo nuevo', 'periodo viejo') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8b16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoteo la Info, coloco el periodo en las columnas y asi calculo las progresiones por Categoria (VCT, VOL y DEB) y Sector\n",
    "df_sector_comparable = df_sector_comparable.pivot_table(values='valores', index=['direccion' ,'numero_operacional', 'punto_operacional', 'categoria', 'sector'], columns='periodo', aggfunc='sum').reset_index()\n",
    "df_sector_comparable['progresion'] = round((df_sector_comparable['periodo nuevo'] / df_sector_comparable['periodo viejo']) - 1, 3)\n",
    "\n",
    "# Sirve luego para calcular las progresiones por SECTOR a nivel FORMATO\n",
    "df_formato_sector_comparable = df_sector_comparable\n",
    "\n",
    "# DF auxiliar para realizar una baja consolidada de informacion\n",
    "df_formato_sector_comparable_aux = df_formato_sector_comparable\n",
    "\n",
    "# Pivoteo la Informacion para mostrar las progresiones por Sector\n",
    "df_progresiones_categoria_sectores = df_sector_comparable.pivot_table(values='progresion', index=['numero_operacional', 'punto_operacional', 'categoria'], columns='sector', aggfunc='sum').reset_index()\n",
    "\n",
    "# Aqui vuelvo a trabajar sobre el DF que contiene las progresiones a NIVEL TIENDA ya que ahora que tengo las progresiones por sector, tengo que unir las progresiones TOTAL TIENDA a las que estan aperturadas por SECTOR. Es por esto que renombro una de sus columnas para luego realizar un concat\n",
    "df_tienda_comparable = df_tienda_comparable.rename(columns={'progresion':'total_tienda'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bd95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora trabajo con un df auxiliar generado arriba para obtener las progresiones por SECTOR a Nivel FORMATO cerrado.\n",
    "df_formato_sector_comparable = df_formato_sector_comparable.groupby(['direccion', 'categoria', 'sector'])[['periodo viejo', 'periodo nuevo']].sum().reset_index()\n",
    "df_formato_sector_comparable['progresion'] = round(df_formato_sector_comparable['periodo nuevo'] / df_formato_sector_comparable['periodo viejo'] - 1, 3)\n",
    "df_formato_sector_comparable = df_formato_sector_comparable.pivot_table(values='progresion', index=['direccion', 'categoria'], columns='sector', aggfunc='sum').reset_index()\n",
    "df_formato_sector_comparable = df_formato_sector_comparable.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9203f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizo un JOIN entre el DF que contiene las Progresiones a NIVEL SECTOR con el DF que contiene las progresiones a nivel TIENDA, lo limpio, ordeno y presento\n",
    "df_progresiones_join_sector_tienda = pd.merge(df_progresiones_categoria_sectores, df_tienda_comparable[['direccion', 'numero_operacional', 'categoria', 'total_tienda']], on=['numero_operacional', 'categoria'], how='left')\n",
    "df_progresiones_join_sector_tienda = df_progresiones_join_sector_tienda.fillna(0)\n",
    "df_progresiones_join_sector_tienda.columns = df_progresiones_join_sector_tienda.columns.str.capitalize().str.strip().str.replace('_', ' ')\n",
    "df_progresiones_join_sector_tienda = df_progresiones_join_sector_tienda.drop(columns=['Numero operacional'])\n",
    "df_progresiones_join_sector_tienda = df_progresiones_join_sector_tienda.rename(columns={'Total tienda': 'Total tienda', 'P.g.c.': 'PGC'})\n",
    "df_progresiones_join_sector_tienda = df_progresiones_join_sector_tienda.sort_values(by='Total tienda', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5d2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabajo ahora para ordenar y concatenar el DF con las Progresiones por Tienda y por Sector para realizar una bajada consolidada donde en una misma vista, tenga en las columnas los valores de las progresiones por VCT, DEB y VOL, aperturado por Sector y Joineado con el Total tienda de esa CATEGORIA\n",
    "df_final_consolidado_tienda = df_tienda_comparable.drop(columns=['periodo viejo', 'periodo nuevo'])\n",
    "df_final_consolidado_tienda = df_final_consolidado_tienda.rename(columns={'total_tienda':'progresion'})\n",
    "df_final_consolidado_tienda['sector'] = 'Total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4653110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora hago los mismo con el DF que contiene las progresiones aperturadas por Categoria.\n",
    "df_final_consolidado_sector = df_sector_comparable.drop(columns=['periodo viejo', 'periodo nuevo'])\n",
    "df_final_consolidado_sector = df_final_consolidado_sector[['direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'progresion', 'sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff110a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez concatenadas, puedo realizar una Tabla Pivote y de esta forma conseguir la hoja de Tiendas Consolidadas, aperturadas por sus categorias, sectores y con el detalle de total tienda\n",
    "df_final_consolidado_total = pd.concat([df_final_consolidado_sector, df_final_consolidado_tienda])\n",
    "df_final_consolidado_total = df_final_consolidado_total.pivot_table(values='progresion', index=['direccion', 'punto_operacional'], columns=['categoria', 'sector'], aggfunc='sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f097fc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan_mera\\AppData\\Local\\Temp\\ipykernel_6640\\3885459734.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_volumen_grupo_de_familia_comparable['mes_num'] = df_volumen_grupo_de_familia_comparable['mes'].map(meses_aux)\n",
      "C:\\Users\\juan_mera\\AppData\\Local\\Temp\\ipykernel_6640\\3885459734.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_volumen_grupo_de_familia_comparable['pivot'] = pd.to_datetime('01/' + df_volumen_grupo_de_familia_comparable['mes_num'].astype(str) + '/' + df_volumen_grupo_de_familia_comparable['año'].astype(str), format='%d/%m/%Y')\n",
      "C:\\Users\\juan_mera\\AppData\\Local\\Temp\\ipykernel_6640\\3885459734.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_volumen_grupo_de_familia_comparable['periodo'] = np.where(df_volumen_grupo_de_familia_comparable['pivot'] > fecha_de_corte, 'periodo nuevo', 'periodo viejo')\n"
     ]
    }
   ],
   "source": [
    "# Ya que ahora tengo las primeras tablas con sus progresiones, comienzo a trabajar sobre el ultimo apartado, especifico sobre el volumen y su apertura por GRUPO DE FAMILIA\n",
    "# Agrupo el DF de Volumen que ya tenia cargado hasta GF\n",
    "df_volumen_grupo_de_familia = df_volumen.groupby(['año', 'mes', 'fecha', 'direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'sector', 'seccion', 'grupo_de_familia'])['valores'].sum().reset_index()\n",
    "\n",
    "# Lo Joineo con el Padron\n",
    "df_volumen_grupo_de_familia_join = pd.merge(df_volumen_grupo_de_familia, padron[['numero_operacional', columna_mes]], on='numero_operacional', how='left')\n",
    "\n",
    "# Me quedo unicamente con los valores comparables\n",
    "df_volumen_grupo_de_familia_comparable = df_volumen_grupo_de_familia_join[df_volumen_grupo_de_familia_join[columna_mes] == 'SC']\n",
    "\n",
    "# Genero una columna Datetime para Pivotear la Info y Separar el nuevo y viejo periodo\n",
    "df_volumen_grupo_de_familia_comparable['mes_num'] = df_volumen_grupo_de_familia_comparable['mes'].map(meses_aux)\n",
    "df_volumen_grupo_de_familia_comparable['pivot'] = pd.to_datetime('01/' + df_volumen_grupo_de_familia_comparable['mes_num'].astype(str) + '/' + df_volumen_grupo_de_familia_comparable['año'].astype(str), format='%d/%m/%Y')\n",
    "df_volumen_grupo_de_familia_comparable['periodo'] = np.where(df_volumen_grupo_de_familia_comparable['pivot'] > fecha_de_corte, 'periodo nuevo', 'periodo viejo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f317879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoteo la informacion para colocar los periodos como columnas y asi poder calcular las progresiones, el GAP y la CMG\n",
    "df_volumen_grupo_de_familia_comparable = df_volumen_grupo_de_familia_comparable.pivot_table(values='valores', index=['direccion', 'grupo_de_familia', 'seccion', 'categoria'], columns='periodo', aggfunc='sum').reset_index()\n",
    "df_volumen_grupo_de_familia_comparable['periodo viejo'] = df_volumen_grupo_de_familia_comparable['periodo viejo'].fillna(0)\n",
    "df_volumen_grupo_de_familia_comparable['GAP'] = df_volumen_grupo_de_familia_comparable['periodo nuevo'] - df_volumen_grupo_de_familia_comparable['periodo viejo']\n",
    "df_volumen_grupo_de_familia_comparable['progresion'] = (df_volumen_grupo_de_familia_comparable['periodo nuevo'] / df_volumen_grupo_de_familia_comparable['periodo viejo']) - 1\n",
    "df_volumen_grupo_de_familia_comparable['progresion'] = df_volumen_grupo_de_familia_comparable['progresion'].replace(np.inf, 0)\n",
    "df_volumen_grupo_de_familia_comparable['progresion'] = df_volumen_grupo_de_familia_comparable['progresion'].replace(np.nan, 0)\n",
    "df_volumen_grupo_de_familia_comparable = df_volumen_grupo_de_familia_comparable.sort_values('progresion', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2206cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero una columnas Auxiliar que contenga el Total periodo viejo por Formato para asi luego calcular la CMG de forma mas facil (Vectorizada) y ahorrar rendimiento\n",
    "df_volumen_grupo_de_familia_comparable['total_periodo_viejo_direccion'] = df_volumen_grupo_de_familia_comparable.groupby('direccion')['periodo viejo'].transform('sum')\n",
    "df_volumen_grupo_de_familia_comparable['Cmg'] = df_volumen_grupo_de_familia_comparable['GAP'] / df_volumen_grupo_de_familia_comparable['total_periodo_viejo_direccion']\n",
    "df_volumen_grupo_de_familia_comparable['Cmg'] = df_volumen_grupo_de_familia_comparable['Cmg'].fillna(0)\n",
    "df_volumen_grupo_de_familia_comparable = df_volumen_grupo_de_familia_comparable.sort_values('Cmg', ascending=False)\n",
    "df_volumen_grupo_de_familia_comparable = df_volumen_grupo_de_familia_comparable.rename(columns={'direccion':'Direccion','grupo_de_familia':'Grupo de familia', 'seccion':'Seccion', 'categoria':'Categoria', 'progresion':'Progresion'})\n",
    "df_volumen_grupo_de_familia_comparable = df_volumen_grupo_de_familia_comparable.drop(columns=['total_periodo_viejo_direccion'])\n",
    "df_volumen_grupo_de_familia_comparable = df_volumen_grupo_de_familia_comparable[['Direccion', 'Grupo de familia', 'Seccion', 'Categoria', 'periodo viejo', 'periodo nuevo', 'GAP', 'Progresion', 'Cmg']]\n",
    "\n",
    "# Ordeno y Concateno todos los DF auxiliares que fui generando para obtener una sola bajada de informacion y en un futuro confeccionar un Giratorio\n",
    "# Genero un DF auxiliar para realizar una bajada consolidada de informacion para generar un giratorio\n",
    "df_tienda_comparable_aux['sector'] = ''\n",
    "df_tienda_comparable_aux = df_tienda_comparable_aux[['direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'sector', 'periodo viejo', 'periodo nuevo', 'progresion']]\n",
    "df_tienda_comparable_aux['aux'] = 'tienda'\n",
    "\n",
    "df_formato_comparable_aux = df_formato_comparable.copy()\n",
    "df_formato_comparable_aux['sector'] = ''\n",
    "df_formato_comparable_aux['numero_operacional'] = ''\n",
    "df_formato_comparable_aux['punto_operacional'] = ''\n",
    "df_formato_comparable_aux = df_formato_comparable_aux[['direccion', 'numero_operacional', 'punto_operacional', 'categoria', 'sector', 'periodo viejo', 'periodo nuevo', 'progresion']]\n",
    "df_formato_comparable_aux['aux'] = 'formato'\n",
    "\n",
    "df_formato_sector_comparable_2_aux = df_formato_sector_comparable_aux.groupby(['direccion', 'categoria', 'sector'])[['periodo viejo', 'periodo nuevo']].sum().reset_index()\n",
    "df_formato_sector_comparable_2_aux['progresion'] = round(df_formato_sector_comparable_2_aux['periodo nuevo'] / df_formato_sector_comparable_2_aux['periodo viejo'] - 1, 3)\n",
    "df_formato_sector_comparable_2_aux['aux'] = 'formato_sector'\n",
    "df_formato_sector_comparable_2_aux['numero_operacional'] = ''\n",
    "df_formato_sector_comparable_2_aux['punto_operacional'] = ''\n",
    "\n",
    "df_formato_sector_comparable_aux['aux'] = 'tienda_sector'\n",
    "\n",
    "df_bajada_consolidada = pd.concat([df_tienda_comparable_aux, df_formato_comparable_aux, df_formato_sector_comparable_aux, df_formato_sector_comparable_2_aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9c1a243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente comienzo a trabajar sobre las progresiones historicas de los formatos con el objetivo de Construir facilmente los graficos que se muestran en los Briefings\n",
    "# Cargo toda la Info\n",
    "try:\n",
    "    deb_acum = pd.read_csv('data/2026/Debitos Acum.csv', encoding='utf-16', header=1, decimal=',')\n",
    "    cols = ['Año', 'Mes', 'Direccion', 'Punto Operacional', 'Ventas c/impuesto']\n",
    "    vct_acum = pd.read_csv('data/2026/Ventas Acum.csv', encoding='utf-16', header=1, usecols=cols)\n",
    "    vol_acum = pd.read_csv('data/2026/Vol Acum.csv', encoding='utf-16', header=1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Error a la hora de cargar los Historicos. ERROR: {e}')\n",
    "\n",
    "# Quito columnas innecesarias\n",
    "deb_acum = deb_acum.drop(columns=['Indicadores'])\n",
    "vol_acum = vol_acum.drop(columns=['Indicadores'])\n",
    "\n",
    "# Renombro Columnas\n",
    "deb_acum = deb_acum.rename(columns={'Cant. Tickets por Local':'valores'})\n",
    "vol_acum = vol_acum.rename(columns={'VOLUMEN':'valores'})\n",
    "vct_acum = vct_acum.rename(columns={'Ventas c/impuesto':'valores'})\n",
    "\n",
    "# Categorizo las valores de los DF's\n",
    "deb_acum['categoria'] = 'deb'\n",
    "vol_acum['categoria'] = 'vol'\n",
    "vct_acum['categoria'] = 'vct'\n",
    "\n",
    "# Convierto sus columnas a Valores Numericos\n",
    "vol_acum['valores'] = pd.to_numeric(vol_acum['valores'].str.replace('.','').str.replace(',', '.'))\n",
    "vct_acum['valores'] = pd.to_numeric(vct_acum['valores'].str.replace('.','').str.replace(',', '.'))\n",
    "deb_acum['valores'] = pd.to_numeric(deb_acum['valores'].str.replace('.', ''))\n",
    "\n",
    "# Concateno los 3 DF's\n",
    "acum_join = pd.concat([deb_acum, vol_acum, vct_acum])\n",
    "\n",
    "# Estandarizo los nombres de las columnas\n",
    "acum_join.columns = acum_join.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "\n",
    "# Me aseguro que su Numero Operacional sea efectivamente un numero\n",
    "acum_join['numero_operacional'] = acum_join['punto_operacional'].str.split(' ').str[0].astype(int)\n",
    "\n",
    "# Joineo con el Padron\n",
    "acum_join = pd.merge(acum_join, padron[['numero_operacional', columna_mes]], how='left')\n",
    "\n",
    "# Genero un DF comparable \n",
    "acum_join_comparable = acum_join[acum_join[columna_mes] == 'SC']\n",
    "acum_join_comparable = acum_join_comparable.rename(columns={'mes':'fecha'})\n",
    "acum_join_comparable['mes'] = acum_join_comparable['fecha'].str.split(' ').str[0]\n",
    "\n",
    "# Genero un DF sup Total\n",
    "acum_join_no_comparable = acum_join\n",
    "acum_join_no_comparable = acum_join_no_comparable.rename(columns={'mes':'fecha'})\n",
    "acum_join_no_comparable['mes'] = acum_join_no_comparable['fecha'].str.split(' ').str[0]\n",
    "\n",
    "# Realizo transformaciones y calculos a ambos df's para conseguir sus progresiones historicas por categoria\n",
    "acum_join_comparable = acum_join_comparable.groupby(['año', 'fecha', 'mes', 'direccion', 'categoria'])['valores'].sum().reset_index()\n",
    "acum_join_no_comparable = acum_join_no_comparable.groupby(['año', 'fecha', 'mes', 'direccion', 'categoria'])['valores'].sum().reset_index()\n",
    "\n",
    "# Genero un Diccionario Auxiliar\n",
    "meses_orden = {'Enero':1, 'Febrero':2, 'Marzo':3, 'Abril':4, 'Mayo':5, 'Junio':6, 'Julio':7, 'Agosto':8, 'Septiembre':9, 'Octubre':10, 'Noviembre':11, 'Diciembre':12}\n",
    "\n",
    "# Genero una columna Auxiliar Mapeando el Diccionario con la Columna Mes\n",
    "acum_join_comparable['aux'] = acum_join_comparable['mes'].map(meses_orden)\n",
    "acum_join_no_comparable['aux'] = acum_join_no_comparable['mes'].map(meses_orden)\n",
    "\n",
    "# Invierto el Diccionario Auxiliar\n",
    "meses_invertidos = {v:k for k, v in meses_orden.items()}\n",
    "\n",
    "# Genero una Columna Datetime concatenando varios elementos de los DF's con el Objetivo de limitar los datos al mes comparable seleccionado\n",
    "acum_join_comparable.sort_values(by='aux', ascending=True)\n",
    "acum_join_comparable['fecha_completa'] = pd.to_datetime(\n",
    "    '01/' + acum_join_comparable['aux'].astype(str) + '/' + acum_join_comparable['año'].astype(str), format='%d/%m/%Y')\n",
    "\n",
    "acum_join_no_comparable.sort_values(by='aux', ascending=True)\n",
    "acum_join_no_comparable['fecha_completa'] = pd.to_datetime(\n",
    "    '01/' + acum_join_no_comparable['aux'].astype(str) + '/' + acum_join_no_comparable['año'].astype(str), format='%d/%m/%Y')\n",
    "\n",
    "# Genero una Variable utilizando el mes comparable para limitar los registros del año \"Vencido\" hasta ese mes en particular\n",
    "fecha_tope = pd.to_datetime('01/'+ str(meses_orden[mes_comparable]) + '/' + str((datetime.today() - timedelta(days=28)).year), format='%d/%m/%Y')\n",
    "\n",
    "# Hago efectivo el limite\n",
    "acum_join_comparable = acum_join_comparable[acum_join_comparable['fecha_completa'] <= fecha_tope]\n",
    "acum_join_no_comparable = acum_join_no_comparable[acum_join_no_comparable['fecha_completa'] <= fecha_tope]\n",
    "\n",
    "# Pivoteo la Informacion para colocar los años como columnas y calcular las progresiones\n",
    "acum_join_comparable = acum_join_comparable.pivot_table(values='valores', columns='año', index=['direccion', 'mes', 'categoria', 'aux'], aggfunc='sum').reset_index()\n",
    "acum_join_no_comparable = acum_join_no_comparable.pivot_table(values='valores', columns='año', index=['direccion', 'mes', 'categoria', 'aux'], aggfunc='sum').reset_index()\n",
    "\n",
    "# Calculo las Progresiones -- DESCOMENTAR LAS PROGRESIONES DE 2026 CUANDO TENGA LA POSIBILIDAD E INFORMACION -- (FEBRERO 2026)\n",
    "acum_join_comparable['progresion 2024'] = round((acum_join_comparable[2024] / acum_join_comparable[2023]) - 1, 3)\n",
    "acum_join_comparable['progresion 2025'] = round((acum_join_comparable[2025] / acum_join_comparable[2024]) - 1, 3)\n",
    "#acum_join_comparable['progresion 2026'] = round((acum_join_comparable[2026] / acum_join_comparable[2025]) - 1, 3)\n",
    "\n",
    "acum_join_no_comparable['progresion 2024'] = round((acum_join_no_comparable[2024] / acum_join_no_comparable[2023]) - 1, 3)\n",
    "acum_join_no_comparable['progresion 2025'] = round((acum_join_no_comparable[2025] / acum_join_no_comparable[2024]) - 1, 3)\n",
    "#acum_join_no_comparable['progresion 2026'] = round((acum_join_no_comparable[2026] / acum_join_no_comparable[2025]) - 1, 3)\n",
    "\n",
    "# Ordeno y Elimino columna Auxiliar\n",
    "acum_join_comparable = acum_join_comparable.sort_values(by=['direccion', 'categoria' ,'aux'], ascending=[True, True, True])\n",
    "acum_join_comparable = acum_join_comparable.drop(columns=['aux'])\n",
    "\n",
    "acum_join_no_comparable = acum_join_no_comparable.sort_values(by=['direccion', 'categoria' ,'aux'], ascending=[True, True, True])\n",
    "acum_join_no_comparable = acum_join_no_comparable.drop(columns=['aux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0cfa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Archivo generado: salida_briefings\\Resultados Briefing E-COMMERCE (12-01-2026).xlsx\n",
      "✔ Archivo generado: salida_briefings\\Resultados Briefing NO INFORMADO (12-01-2026).xlsx\n",
      "✔ Archivo generado: salida_briefings\\Resultados Briefing PROXIMIDAD (12-01-2026).xlsx\n",
      "✔ Archivo generado: salida_briefings\\Resultados Briefing MAXI (12-01-2026).xlsx\n",
      "✔ Archivo generado: salida_briefings\\Resultados Briefing MARKET (12-01-2026).xlsx\n",
      "✔ Archivo generado: salida_briefings\\Resultados Briefing HIPERMERCADO (12-01-2026).xlsx\n",
      "✔ Giratorio generado: salida_briefings\\Base Giratorio.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Exporto todo a Excel\n",
    "formatos = df_tienda_comparable['direccion'].unique().tolist()\n",
    "categorias = ['vct', 'deb', 'vol']\n",
    "\n",
    "# Carpeta de salida\n",
    "output_dir = \"salida_briefings\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "formatos = df_tienda_comparable['direccion'].unique().tolist()\n",
    "categorias = ['vct', 'deb', 'vol']\n",
    "\n",
    "try:\n",
    "    for formato in formatos:\n",
    "        file_name = f\"Resultados Briefing {formato.upper()} ({datetime.today().strftime('%d-%m-%Y')}).xlsx\"\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "        with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "\n",
    "            df_formato_comparable_final[\n",
    "                df_formato_comparable_final['direccion'] == formato\n",
    "            ].to_excel(writer, sheet_name=f'Total Categoria - {formato[0:3]}', index=False)\n",
    "\n",
    "            df_formato_no_comparable_final[\n",
    "                df_formato_no_comparable_final['direccion'] == formato\n",
    "            ].to_excel(writer, sheet_name=f'Total Categoria (Sup Total) - {formato[0:3]}'[:31], index=False)\n",
    "\n",
    "            df_formato_sector_comparable[\n",
    "                df_formato_sector_comparable['direccion'] == formato\n",
    "            ].to_excel(writer, sheet_name=f'Total Categoria x Sector - {formato[0:3]}', index=False)\n",
    "\n",
    "            for categoria in categorias:\n",
    "                df_filtrado = df_progresiones_join_sector_tienda[\n",
    "                    (df_progresiones_join_sector_tienda['Categoria'] == categoria) &\n",
    "                    (df_progresiones_join_sector_tienda['Direccion'] == formato)\n",
    "                ].drop(columns=['Direccion'])\n",
    "\n",
    "                df_filtrado.to_excel(writer, sheet_name=f'{categoria} - {formato[0:3]}', index=False)\n",
    "\n",
    "            df_final_consolidado_total[\n",
    "                df_final_consolidado_total['direccion'] == formato\n",
    "            ].to_excel(writer, sheet_name=f'Info Consolidada - {formato[0:3]}', index=True)\n",
    "\n",
    "            df_volumen_grupo_de_familia_comparable[\n",
    "                df_volumen_grupo_de_familia_comparable['Direccion'] == formato\n",
    "            ].to_excel(writer, sheet_name=f'GF Consolidada - {formato[0:3]}', index=False)\n",
    "\n",
    "            acum_join_comparable[\n",
    "                acum_join_comparable['direccion'] == formato\n",
    "            ].to_excel(writer, sheet_name=f'Progresiones comp - {formato[0:3]}', index=False)\n",
    "\n",
    "            acum_join_no_comparable[\n",
    "                acum_join_no_comparable['direccion'] == formato\n",
    "            ].to_excel(writer, sheet_name=f'Progresiones total - {formato[0:3]}', index=False)\n",
    "\n",
    "        print(f\"✔ Archivo generado: {file_path}\")\n",
    "\n",
    "    # Archivo giratorio\n",
    "    giratorio_path = os.path.join(output_dir, \"Base Giratorio.xlsx\")\n",
    "    with pd.ExcelWriter(giratorio_path, engine='xlsxwriter') as writer:\n",
    "        df_bajada_consolidada.to_excel(writer, sheet_name=\"Base Giratorio\", index=False)\n",
    "\n",
    "    print(f\"✔ Giratorio generado: {giratorio_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al generar los archivos: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
